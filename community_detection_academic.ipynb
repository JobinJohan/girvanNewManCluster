{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Community detection in an academic network\n",
    "## Aim\n",
    "<ol>\n",
    "  <li> Load social graph</li>\n",
    "  <li> Run community detection and centrality methods</li>\n",
    "  <li> Visualize the network </li>\n",
    "</ol>\n",
    "\n",
    "## Tasks\n",
    "<ol>\n",
    "    <li> <strong>Load the dataset:</strong> Load the Author Network dataset provided at <a href:\"https://aminer.org/lab-datasets/soinf/\">https://aminer.org/lab-datasets/soinf/</a>\n",
    "The graph consists of authors and coauthor relationships.\n",
    "  </li>\n",
    "    <li> <strong>Implementation:</strong> \n",
    "        <ol>\n",
    "            <li> Implement Girvan-Newman clustering algorithm till 10th iteration level.</li>\n",
    "            <li> Implement Pagerank algorithm.</li>\n",
    "            <li> Implement Betweenness centrality measure</li>\n",
    "        <strong>Use the previous implementation, perform the following tasks</strong>\n",
    "            <li> Use Girvan-Newman algorithm to find clusters of authors</li>\n",
    "            <li> Find the top-10 authors with highest betweenness centrality</li>      \n",
    "        </ol>\n",
    "    </li>\n",
    "    <li> <strong>Visualization: </strong> \n",
    "        <ol>\n",
    "            <li> Visualize the output of Girvan-Newman algorithm by coloring nodes according to their assigned groups</li>\n",
    "            <li> Visualize the network and highlight the top 10 authors with the highest betweeness centrality and top 10 edges with the highest betweenness centrality</li>      \n",
    "        </ol>\n",
    "    </li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> All necessary modules imported\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Utility class to pretty print dictionary\n",
    "class DictTable(dict):\n",
    "    # Overridden dict class which takes a dict in the form {'a': 2, 'b': 3},\n",
    "    # and renders an HTML Table in IPython Notebook.\n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table width=100%>\"]\n",
    "        for key, value in iter(self.items()):\n",
    "            html.append(\"<tr>\")\n",
    "            html.append(\"<td>{0}</td>\".format(key))\n",
    "            html.append(\"<td>{0}</td>\".format(str(len(value))+\" \"+\"graph[s] of size: \"+str([len(x) for x in value])+\" nodes\"))\n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)\n",
    "print(\"> All necessary modules imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> All data loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width=100%><tr><td>Web Mining/Information Fusion</td><td>3 graph[s] of size: [9, 348, 11] nodes</td></tr><tr><td>Information Retrieval</td><td>2 graph[s] of size: [7, 657] nodes</td></tr><tr><td>Web Services</td><td>2 graph[s] of size: [400, 7] nodes</td></tr><tr><td>Semantic Web/Description Logics</td><td>2 graph[s] of size: [671, 10] nodes</td></tr><tr><td>Database Systems/XML Data</td><td>1 graph[s] of size: [1127] nodes</td></tr><tr><td>Machine Learning</td><td>1 graph[s] of size: [976] nodes</td></tr><tr><td>Bayesian Networks/Belief function</td><td>1 graph[s] of size: [554] nodes</td></tr><tr><td>Data Mining/Association Rules</td><td>1 graph[s] of size: [679] nodes</td></tr></table>"
      ],
      "text/plain": [
       "{'Web Mining/Information Fusion': [<networkx.classes.graph.Graph at 0x10f3bc320>,\n",
       "  <networkx.classes.graph.Graph at 0x11e5a1f60>,\n",
       "  <networkx.classes.graph.Graph at 0x11e629518>],\n",
       " 'Information Retrieval': [<networkx.classes.graph.Graph at 0x11e62a748>,\n",
       "  <networkx.classes.graph.Graph at 0x11e62a9e8>],\n",
       " 'Web Services': [<networkx.classes.graph.Graph at 0x11e74d0f0>,\n",
       "  <networkx.classes.graph.Graph at 0x11e915278>],\n",
       " 'Semantic Web/Description Logics': [<networkx.classes.graph.Graph at 0x11e7d56d8>,\n",
       "  <networkx.classes.graph.Graph at 0x11ec42438>],\n",
       " 'Database Systems/XML Data': [<networkx.classes.graph.Graph at 0x11e7d5cf8>],\n",
       " 'Machine Learning': [<networkx.classes.graph.Graph at 0x11ec4eeb8>],\n",
       " 'Bayesian Networks/Belief function': [<networkx.classes.graph.Graph at 0x11edcab00>],\n",
       " 'Data Mining/Association Rules': [<networkx.classes.graph.Graph at 0x11ee9c1d0>]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "DATASET = \"./data\"\n",
    "\n",
    "def loadData(directoryPath):\n",
    "    \"\"\"Load the data of all files of the folder given in parameter.\"\"\"\n",
    "    files = os.listdir(directoryPath)\n",
    "    # dictionary wrt to the following format: {topic1:[[network1],[network2]]}\n",
    "    allGraphsOfEachTopic = {}\n",
    "    for file in files:\n",
    "        topic = \"\"\n",
    "        if \"T107\" in file:\n",
    "            topic = \"Web Services\"\n",
    "        elif \"T131\" in file:\n",
    "            topic = \"Bayesian Networks/Belief function\"\n",
    "        elif \"T144\" in file:\n",
    "            topic = \"Web Mining/Information Fusion\"\n",
    "        elif \"T145\" in file:\n",
    "            topic = \"Semantic Web/Description Logics\"\n",
    "        elif \"T162\" in file:\n",
    "            topic = \"Machine Learning\"\n",
    "        elif \"T16\" in file:\n",
    "            topic = \"Data Mining/Association Rules\"\n",
    "        elif \"T24\" in file:\n",
    "            topic = \"Database Systems/XML Data\"\n",
    "        elif \"T75\" in file:\n",
    "            topic = \"Information Retrieval\"\n",
    "        else:\n",
    "            topic = \"Unknown\"\n",
    "\n",
    "        graphToBuild = nx.Graph()\n",
    "        \n",
    "        # for naming purposes\n",
    "        subStart = file.find('sub')\n",
    "        subEnd = file.find('.')\n",
    "        graphToBuild.name = topic.replace('/', ' ').replace(' ', '') + '_{}'.format(file[subStart:subEnd])\n",
    "\n",
    "        # constant\n",
    "        VERTEX = 0\n",
    "        EDGE = 1\n",
    "        TRIANGLE = 2\n",
    "\n",
    "        f = open(DATASET+\"/\"+file)\n",
    "\n",
    "        # Vertices: Int \"String\" Int -> NodeID, personName, #papers\n",
    "        # Edges: Int Int Int -> sourceNodeID, DestNodeID, #coauthoredPapers\n",
    "        # Triangles: Int,Int,Int,Int -> NodeID1, NodeID2, NodeID3, #coauthoredPapers\n",
    "        for line in f:\n",
    "            if \"*Vertices\" in line:\n",
    "                typeOfLine = VERTEX\n",
    "            elif \"*Edges\" in line:\n",
    "                typeOfLine = EDGE\n",
    "            elif \"*Triangles\" in line:\n",
    "                typeOfLine = TRIANGLE\n",
    "            else:\n",
    "                if typeOfLine == VERTEX:\n",
    "                    graph_edge_list = []\n",
    "                    \n",
    "                    for index, s in enumerate(re.split('\"', line)):\n",
    "                        if (index == 1):\n",
    "                            graph_edge_list.append(s)\n",
    "                        else:\n",
    "                            graph_edge_list.append(s.replace(' ','').replace('\\n', ''))\n",
    "                            \n",
    "                    graphToBuild.add_node(graph_edge_list[0], name=graph_edge_list[1], nbpapers=graph_edge_list[2])\n",
    "                elif typeOfLine == EDGE:\n",
    "                    graph_edge_list = line.split()\n",
    "                    graphToBuild.add_edge(graph_edge_list[0], graph_edge_list[1], coauthoredPapers=graph_edge_list[2])\n",
    "                elif typeOfLine == TRIANGLE:\n",
    "                    graph_edge_list = line.split(',')\n",
    "                    graph_edge_list[3] = graph_edge_list[3].replace('\\n', '')\n",
    "                    graphToBuild.add_edge(graph_edge_list[0], graph_edge_list[1], coauthoredPapersTriangle=graph_edge_list[3])\n",
    "                    graphToBuild.add_edge(graph_edge_list[0], graph_edge_list[2], coauthoredPapersTriangle=graph_edge_list[3])\n",
    "                    graphToBuild.add_edge(graph_edge_list[1], graph_edge_list[2], coauthoredPapersTriangle=graph_edge_list[3])\n",
    "\n",
    "        if topic in allGraphsOfEachTopic:\n",
    "            allGraphsOfEachTopic[topic].append(graphToBuild)\n",
    "        else:\n",
    "            allGraphsOfEachTopic[topic] = [graphToBuild]\n",
    "\n",
    "    return allGraphsOfEachTopic\n",
    "\n",
    "allData = loadData(DATASET)\n",
    "print(\"> All data loaded\")\n",
    "DictTable(allData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation\n",
    "## 2A. Implementation of Girvan-Newman clustering till 10th iteration level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def listAuthorsClusters(G):\n",
    "    if not os.path.exists('./Output/GirvanNewman/ClustersTxt'):\n",
    "        os.makedirs('./Output/GirvanNewman/ClustersTxt')\n",
    "    \n",
    "    connected_components = nx.connected_component_subgraphs(G)\n",
    "    \n",
    "    f = open('./Output/GirvanNewman/ClustersTxt/{}.txt'.format(G.name), 'w')\n",
    "    for index, sg in enumerate(connected_components):\n",
    "        f.write('######## Cluster {:2} #######\\n'.format(index))\n",
    "        for node in sg.nodes:\n",
    "            f.write('> {}\\n'.format(G.node[node]['name']))\n",
    "        f.write('\\n\\n')\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def findConcernedEdges(pathsThatContainKey, highestEdge):\n",
    "    ''' Finds which edges are impacted by the removal of the edge that has the highest centrality'''\n",
    "    concernedPaths = []\n",
    "    for path in pathsThatContainKey[highestEdge[0]]:\n",
    "        try:\n",
    "            index = path.index(highestEdge[0])\n",
    "            if path[index + 1] == highestEdge[1]:\n",
    "                concernedPaths.append(path)\n",
    "        except:\n",
    "            pass\n",
    "    print('Concerned PATHS: ', concernedPaths)\n",
    "    concernedEdges = []\n",
    "    # create tuples from paths: ['1','5','7','3'] -> [('1','5'),('5','7'),('7','3')]\n",
    "    for path in concernedPaths:\n",
    "        y = path[1:]\n",
    "        concernedEdges += list(zip(path, y))\n",
    "        \n",
    "    # remove duplicates\n",
    "    concernedEdges = list(dict.fromkeys(concernedEdges))\n",
    "    \n",
    "    # reorder edges. Otherwise, ('6','11') would be different from ('11','6').\n",
    "    concernedEdges = [(y,x) if int(y) < int(x) else (x,y) for (x,y) in concernedEdges]\n",
    "    \n",
    "    # remove highestEdge in order not to recompute its centrality afterwards (it will be 0).\n",
    "    concernedEdges.remove(highestEdge)\n",
    "\n",
    "    return concernedEdges\n",
    "\n",
    "def girvanNewmanClustering(graph, nbIteration, visualization = False):\n",
    "    print('Girvan-Newman on graph \"{}\", {} iterations'.format(graph.name, nbIteration))\n",
    "    \n",
    "    if visualization == True:\n",
    "         # Draw first plot in figure and use variable cnt to handle positions\n",
    "        fig = plt.figure(figsize=(50, 50))\n",
    "        drawGraphs(graph, 1)\n",
    "        cnt = 2\n",
    "   \n",
    "    \n",
    "    # If there are no edge in the graph\n",
    "    if len(list(graph.edges)) == 0:\n",
    "        return \"Empty graph\"\n",
    "    \n",
    "    # At the beginning, we need to compute the centrality for all edges. So all edges are \"concerned\"\n",
    "    concernedEdges = list(graph.edges)\n",
    "    \n",
    "    # init centralities dictionary: {edge: [centrality (for sorting purposes), edge]}\n",
    "    centralities = {}\n",
    "\n",
    "    # While there are edges in the graph and that the number of iteration is biggger than 0\n",
    "    while(len(list(graph.edges)) > 0 and nbIteration > 0):\n",
    "        #firstIteration = True\n",
    "        print(\"\\n\\nRemaining iterations: \", nbIteration)\n",
    "        nbIteration = nbIteration - 1\n",
    "        \n",
    "        # Get all edges of the current graph\n",
    "        edges = list(graph.edges)\n",
    "        \n",
    "        # Compute all shortest paths\n",
    "        shortestPaths = list(nx.all_pairs_shortest_path(graph))\n",
    "        \n",
    "        if len(shortestPaths) ==0:\n",
    "            break\n",
    "\n",
    "        # basic list containing each shortest path -> [path1, path2, path3, ..., pathN]\n",
    "        allShortestPaths = []\n",
    "\n",
    "        # dictionary that links a node to all paths in which it appears -> {'1': [listOfPaths], ...}\n",
    "        pathsThatContainKey = {}\n",
    "\n",
    "        for index, vi in enumerate(shortestPaths):\n",
    "            pathsThatContainKey[str(index + 1)] = []\n",
    "            values = list(vi[1].values())\n",
    "\n",
    "            for path in values:\n",
    "                allShortestPaths.append(path)\n",
    "                for elem in path:\n",
    "                    pathsThatContainKey.setdefault(elem, []).append(path)\n",
    "\n",
    "                    \n",
    "        print('CONCERNED EDGES: ', concernedEdges)\n",
    "        for edge in concernedEdges:\n",
    "            # recompute centrality only for edges whose centrality value changes\n",
    "            # first iteration -> all edges\n",
    "            centrality = edgesBetweennessCentrality(allShortestPaths, pathsThatContainKey, edge)\n",
    "            centralities[edge] = [centrality, edge]\n",
    "            \n",
    "        print(sorted(centralities.values(), reverse=True))\n",
    "        \n",
    "        # get edge with the highest centrality and the centrality value\n",
    "        highestScore, highestEdge = sorted(centralities.values(), reverse=True)[0]\n",
    "        print('HIGHEST EDGE: ', highestEdge, highestScore)\n",
    "        \n",
    "        # find the edges impacted with the removal of 'highestEdge'\n",
    "        concernedEdges = findConcernedEdges(pathsThatContainKey, highestEdge)\n",
    "                \n",
    "        # Remove the edge with the highest centrality\n",
    "        graph.remove_edge(highestEdge[0], highestEdge[1])\n",
    "        rmvd = centralities.pop(highestEdge, None)\n",
    "        print('Removed from centrality dictionary', rmvd)\n",
    "        \n",
    "        if visualization == True:\n",
    "            # Draw the graph with the removed edge into the figure\n",
    "            drawGraphs(graph, cnt)\n",
    "            cnt += 1\n",
    "        \n",
    "    \n",
    "    if visualization == True:\n",
    "        # Draw the original graph with colors to detect communities and save the figure\n",
    "        print(\"Drawing...\")\n",
    "        drawColoredGraph(graph)\n",
    "        print(\"Drawing done\")\n",
    "        if not os.path.exists('./Output/GirvanNewman/Figures'):\n",
    "            os.makedirs('./Output/GirvanNewman/Figures')\n",
    "    \n",
    "        plt.savefig(\"./Output/GirvanNewman/Figures/{}.png\".format(graph.name))\n",
    "        print(\"> Figure saved\")\n",
    "    \n",
    "    print('Saving clusters composition...')\n",
    "    listAuthorsClusters(graph)\n",
    "    print('> Clusters composition saved')                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:magenta\">**Je teste ci-dessous poulet, faut voir l'output pour voir si ça tient la route** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girvan-Newman on graph \"WebMiningInformationFusion_sub27\", 10 iterations\n",
      "\n",
      "\n",
      "Remaining iterations:  10\n",
      "CONCERNED EDGES:  [('1', '2'), ('1', '9'), ('1', '7'), ('2', '3'), ('2', '9'), ('2', '7'), ('3', '9'), ('4', '5'), ('4', '7'), ('5', '7'), ('6', '9'), ('7', '9'), ('8', '9')]\n",
      "[[0.1111111111111111, ('2', '7')], [0.09876543209876543, ('8', '9')], [0.09876543209876543, ('6', '9')], [0.09876543209876543, ('2', '3')], [0.08641975308641975, ('7', '9')], [0.08641975308641975, ('5', '7')], [0.08641975308641975, ('4', '7')], [0.037037037037037035, ('3', '9')], [0.037037037037037035, ('2', '9')], [0.037037037037037035, ('1', '9')], [0.037037037037037035, ('1', '7')], [0.024691358024691357, ('1', '2')], [0.012345679012345678, ('4', '5')]]\n",
      "HIGHEST EDGE:  ('2', '7') 0.1111111111111111\n",
      "Concerned PATHS:  [['2', '7'], ['2', '7', '4'], ['2', '7', '5'], ['3', '2', '7'], ['3', '2', '7', '4'], ['3', '2', '7', '5']]\n",
      "Removed from centrality dictionary [0.1111111111111111, ('2', '7')]\n",
      "\n",
      "\n",
      "Remaining iterations:  9\n",
      "CONCERNED EDGES:  [('4', '7'), ('5', '7'), ('2', '3')]\n",
      "[[0.09876543209876543, ('8', '9')], [0.09876543209876543, ('6', '9')], [0.08641975308641975, ('7', '9')], [0.08641975308641975, ('5', '7')], [0.08641975308641975, ('4', '7')], [0.037037037037037035, ('3', '9')], [0.037037037037037035, ('2', '9')], [0.037037037037037035, ('1', '9')], [0.037037037037037035, ('1', '7')], [0.024691358024691357, ('2', '3')], [0.024691358024691357, ('1', '2')], [0.012345679012345678, ('4', '5')]]\n",
      "HIGHEST EDGE:  ('8', '9') 0.09876543209876543\n",
      "Concerned PATHS:  [['8', '9'], ['8', '9', '1'], ['8', '9', '2'], ['8', '9', '3'], ['8', '9', '6'], ['8', '9', '7'], ['8', '9', '7', '4'], ['8', '9', '7', '5']]\n",
      "Removed from centrality dictionary [0.09876543209876543, ('8', '9')]\n",
      "\n",
      "\n",
      "Remaining iterations:  8\n",
      "CONCERNED EDGES:  [('1', '9'), ('2', '9'), ('3', '9'), ('6', '9'), ('7', '9'), ('4', '7'), ('5', '7')]\n",
      "[[0.1076923076923077, ('6', '9')], [0.09230769230769231, ('5', '7')], [0.09230769230769231, ('4', '7')], [0.07692307692307693, ('7', '9')], [0.07692307692307693, ('3', '9')], [0.037037037037037035, ('1', '7')], [0.03076923076923077, ('2', '9')], [0.03076923076923077, ('1', '9')], [0.024691358024691357, ('2', '3')], [0.024691358024691357, ('1', '2')], [0.012345679012345678, ('4', '5')]]\n",
      "HIGHEST EDGE:  ('6', '9') 0.1076923076923077\n",
      "Concerned PATHS:  [['6', '9'], ['6', '9', '1'], ['6', '9', '2'], ['6', '9', '3'], ['6', '9', '7'], ['6', '9', '7', '4'], ['6', '9', '7', '5']]\n",
      "Removed from centrality dictionary [0.1076923076923077, ('6', '9')]\n",
      "\n",
      "\n",
      "Remaining iterations:  7\n",
      "CONCERNED EDGES:  [('1', '9'), ('2', '9'), ('3', '9'), ('7', '9'), ('4', '7'), ('5', '7')]\n",
      "[[0.09803921568627451, ('5', '7')], [0.09803921568627451, ('4', '7')], [0.0784313725490196, ('7', '9')], [0.0784313725490196, ('3', '9')], [0.037037037037037035, ('1', '7')], [0.024691358024691357, ('2', '3')], [0.024691358024691357, ('1', '2')], [0.0196078431372549, ('2', '9')], [0.0196078431372549, ('1', '9')], [0.012345679012345678, ('4', '5')]]\n",
      "HIGHEST EDGE:  ('5', '7') 0.09803921568627451\n",
      "Concerned PATHS:  [['5', '7'], ['5', '7', '1'], ['5', '7', '9'], ['5', '7', '1', '2'], ['5', '7', '9', '3']]\n",
      "Removed from centrality dictionary [0.09803921568627451, ('5', '7')]\n",
      "\n",
      "\n",
      "Remaining iterations:  6\n",
      "CONCERNED EDGES:  [('1', '7'), ('7', '9'), ('1', '2'), ('3', '9')]\n",
      "[[0.17647058823529413, ('1', '7')], [0.1568627450980392, ('1', '2')], [0.09803921568627451, ('4', '7')], [0.0784313725490196, ('7', '9')], [0.0784313725490196, ('3', '9')], [0.024691358024691357, ('2', '3')], [0.0196078431372549, ('2', '9')], [0.0196078431372549, ('1', '9')], [0.012345679012345678, ('4', '5')]]\n",
      "HIGHEST EDGE:  ('1', '7') 0.17647058823529413\n",
      "Concerned PATHS:  [['1', '7'], ['1', '7', '4'], ['1', '7', '4', '5'], ['2', '1', '7'], ['2', '1', '7', '4'], ['2', '1', '7', '4', '5']]\n",
      "Removed from centrality dictionary [0.17647058823529413, ('1', '7')]\n",
      "\n",
      "\n",
      "Remaining iterations:  5\n",
      "CONCERNED EDGES:  [('4', '7'), ('4', '5'), ('1', '2')]\n",
      "[[0.23529411764705882, ('4', '7')], [0.1568627450980392, ('4', '5')], [0.0784313725490196, ('7', '9')], [0.0784313725490196, ('3', '9')], [0.0392156862745098, ('1', '2')], [0.024691358024691357, ('2', '3')], [0.0196078431372549, ('2', '9')], [0.0196078431372549, ('1', '9')]]\n",
      "HIGHEST EDGE:  ('4', '7') 0.23529411764705882\n",
      "Concerned PATHS:  [['4', '7'], ['4', '7', '9'], ['4', '7', '9', '1'], ['4', '7', '9', '2'], ['4', '7', '9', '3'], ['5', '4', '7'], ['5', '4', '7', '9'], ['5', '4', '7', '9', '1'], ['5', '4', '7', '9', '2'], ['5', '4', '7', '9', '3']]\n",
      "Removed from centrality dictionary [0.23529411764705882, ('4', '7')]\n",
      "\n",
      "\n",
      "Remaining iterations:  4\n",
      "CONCERNED EDGES:  [('7', '9'), ('1', '9'), ('2', '9'), ('3', '9'), ('4', '5')]\n",
      "[[0.12903225806451613, ('7', '9')], [0.06451612903225806, ('3', '9')], [0.06451612903225806, ('2', '9')], [0.06451612903225806, ('1', '9')], [0.0392156862745098, ('1', '2')], [0.03225806451612903, ('4', '5')], [0.024691358024691357, ('2', '3')]]\n",
      "HIGHEST EDGE:  ('7', '9') 0.12903225806451613\n",
      "Concerned PATHS:  [['7', '9'], ['7', '9', '1'], ['7', '9', '2'], ['7', '9', '3']]\n",
      "Removed from centrality dictionary [0.12903225806451613, ('7', '9')]\n",
      "\n",
      "\n",
      "Remaining iterations:  3\n",
      "CONCERNED EDGES:  [('1', '9'), ('2', '9'), ('3', '9')]\n",
      "[[0.043478260869565216, ('3', '9')], [0.043478260869565216, ('2', '9')], [0.043478260869565216, ('1', '9')], [0.0392156862745098, ('1', '2')], [0.03225806451612903, ('4', '5')], [0.024691358024691357, ('2', '3')]]\n",
      "HIGHEST EDGE:  ('3', '9') 0.043478260869565216\n",
      "Concerned PATHS:  [['3', '9']]\n",
      "Removed from centrality dictionary [0.043478260869565216, ('3', '9')]\n",
      "\n",
      "\n",
      "Remaining iterations:  2\n",
      "CONCERNED EDGES:  []\n",
      "[[0.043478260869565216, ('2', '9')], [0.043478260869565216, ('1', '9')], [0.0392156862745098, ('1', '2')], [0.03225806451612903, ('4', '5')], [0.024691358024691357, ('2', '3')]]\n",
      "HIGHEST EDGE:  ('2', '9') 0.043478260869565216\n",
      "Concerned PATHS:  [['2', '9'], ['3', '2', '9']]\n",
      "Removed from centrality dictionary [0.043478260869565216, ('2', '9')]\n",
      "\n",
      "\n",
      "Remaining iterations:  1\n",
      "CONCERNED EDGES:  [('2', '3')]\n",
      "[[0.17391304347826086, ('2', '3')], [0.043478260869565216, ('1', '9')], [0.0392156862745098, ('1', '2')], [0.03225806451612903, ('4', '5')]]\n",
      "HIGHEST EDGE:  ('2', '3') 0.17391304347826086\n",
      "Concerned PATHS:  [['2', '3'], ['9', '1', '2', '3']]\n",
      "Removed from centrality dictionary [0.17391304347826086, ('2', '3')]\n",
      "Saving clusters composition...\n",
      "> Clusters composition saved\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "graph = allData['Web Mining/Information Fusion'][0]\n",
    "girvanNewmanClustering(graph.copy(),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B. Implementation of Pagerank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pageRankCentrality(graph, alpha, beta):\n",
    "    # Transposition of matrix\n",
    "    adjacencyMatrix = nx.to_numpy_matrix(graph, weight='None')\n",
    "    amTransposed = np.transpose(adjacencyMatrix)\n",
    "\n",
    "    # Diagonal Matrix\n",
    "    diagonalMatrix = np.zeros([adjacencyMatrix.shape[0], adjacencyMatrix.shape[1]])\n",
    "    row, col = np.diag_indices(diagonalMatrix.shape[0])\n",
    "    # Compute the values that have to be filled into the diagonal\n",
    "    diagonalMatrix[row, col] = [1 / degree[1] for degree in list(graph.degree())]\n",
    "\n",
    "    # Identity matrix\n",
    "    identityMatrix = np.identity(adjacencyMatrix.shape[0])\n",
    "\n",
    "    # Vector of ones\n",
    "    ones = np.ones((adjacencyMatrix.shape[0], 1))\n",
    "    pageRankCentrality = np.dot(beta * np.linalg.inv((identityMatrix - np.dot(alpha * amTransposed, diagonalMatrix))), ones)\n",
    "\n",
    "    return pageRankCentrality\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C. Implementation of the betweenness centrality measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgesBetweennessCentrality(allShortestPaths, pathsThatContainKey, edge):\n",
    "    \"\"\"computes the betweenness centrality of a given edge\"\"\"\n",
    "    # Initialization of variables to compute centrality of each edge\n",
    "    #centrality=0\n",
    "    nbPathsIncludingEdge=0\n",
    "    #counterShortestPath=0\n",
    "            \n",
    "    # For all shortestPath, count the number of them that contain the current edge \n",
    "    #for vi in allShortestPaths:\n",
    "        #nbPathsIncludingEdge += edgeIsInPath([edge[0], edge[1]], vi)\n",
    "        #nbPathsIncludingEdge += edgeIsInPath(edge, allShortestPaths, pathsThatContainKey)\n",
    "        #counterShortestPath+=1\n",
    "            \n",
    "    for index, p in enumerate(pathsThatContainKey[edge[0]]):\n",
    "        try:\n",
    "            index = p.index(edge[0])\n",
    "            if p[index + 1] == edge[1]:\n",
    "                nbPathsIncludingEdge += 1\n",
    "                continue\n",
    "                \n",
    "            # case where the edge is in reversed order ('11', '6') instead of ('6', '11')\n",
    "            # It should never be the case but it is still better to test it\n",
    "            index = p.index(edge[1])\n",
    "            if p[index + 1] == edge[0]:\n",
    "                nbPathsIncludingEdge += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    # Centrality = Number of shortest paths including the edge / total number of shortest paths       \n",
    "    centrality = nbPathsIncludingEdge / len(allShortestPaths)\n",
    "    #print(nbPathsIncludingEdge, len(allShortestPaths), centrality)\n",
    "    return centrality\n",
    "\n",
    "#def edgeIsInPath(edge, path):\n",
    "#    \"\"\"checks if an edge is contained in a path of an undirected graph (the path is a list of nodes)\"\"\"\n",
    "#    edge1= [edge[0],edge[1]]\n",
    "#    edge2= [edge[1],edge[0]]\n",
    "#    print('edge 1: {}, edge 2: {}, path: {}'.format(edge1, edge2, path))\n",
    "#    if all(i in path for i in edge1) or all(i in path for i in edge2):\n",
    "#        return 1\n",
    "#    else:\n",
    "#        return 0\n",
    "\n",
    "    \n",
    "def nodeIsInPath(node, path):\n",
    "    \"\"\"checks if an edge is contained in a path of an undirected graph (the path is a list of nodes)\"\"\"\n",
    "    if node in path:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def nodesBetweennessCentrality(listOfAllShortestPath, node, graph):\n",
    "    \"\"\"betweenness centrality of a given node: used in task 2E\"\"\"\n",
    "    centrality = 0\n",
    "    nbPathsIncludingNode=0\n",
    "    counterShortestPath=0\n",
    "    \n",
    "    for vi in listOfAllShortestPath:\n",
    "        nbPathsIncludingNode += nodeIsInPath(node, vi)\n",
    "        counterShortestPath+=1\n",
    "        \n",
    "    centrality = nbPathsIncludingNode/counterShortestPath\n",
    "    return centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D. Use Girvan-Newman algorithm to find clusters of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Topic \"Web Mining/Information Fusion\"\"\n",
      "> Girvan-Newman clustering for WebMiningInformationFusion_sub27\n",
      "Girvan-Newman on graph \"WebMiningInformationFusion_sub27\", 10 iterations\n",
      "Remaining iterations:  10\n",
      "test111\n",
      "test222 45\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "Remaining iterations:  9\n",
      "test111\n",
      "test222 45\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "Remaining iterations:  8\n",
      "test111\n",
      "test222 45\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Remaining iterations:  7\n",
      "test111\n",
      "test222 45\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Remaining iterations:  6\n",
      "test111\n",
      "test222 14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Remaining iterations:  5\n",
      "test111\n",
      "test222 14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Remaining iterations:  4\n",
      "test111\n",
      "test222 5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Remaining iterations:  3\n",
      "test111\n",
      "test222 3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Remaining iterations:  2\n",
      "test111\n",
      "test222 1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Remaining iterations:  1\n",
      "test111\n",
      "test222 1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Saving clusters composition...\n",
      "> Clusters composition saved\n",
      "> Girvan-Newman clustering for WebMiningInformationFusion_sub4\n",
      "Girvan-Newman on graph \"WebMiningInformationFusion_sub4\", 10 iterations\n",
      "Remaining iterations:  10\n",
      "test111\n",
      "test222 60726\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3f67541304d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistOfGraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> Girvan-Newman clustering for {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mgirvanNewmanClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-d7d08204dd25>\u001b[0m in \u001b[0;36mgirvanNewmanClustering\u001b[0;34m(graph, nbIteration, visualization)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mcentrality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medgesBetweenessCentrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallShortestPaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;31m# Keep the edge with the highest centrality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcentrality\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhighestScore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c8ae1c604ce0>\u001b[0m in \u001b[0;36medgesBetweenessCentrality\u001b[0;34m(allShortestPath, edge)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# For all shortestPath, count the number of them that contain the current edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallShortestPath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mnbPathsIncludingEdge\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0medgeIsInPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcounterShortestPath\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c8ae1c604ce0>\u001b[0m in \u001b[0;36medgeIsInPath\u001b[0;34m(edge, path)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0medge1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0medge2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medge1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medge2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c8ae1c604ce0>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0medge1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0medge2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medge1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medge2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# runs Girvan-Newman for every graph in the dataset\n",
    "for topic, listOfGraphs in allData.items():\n",
    "    print('>>> Topic \"{}\"\"'.format(topic))\n",
    "    for graph in listOfGraphs:\n",
    "        print('> Girvan-Newman clustering for {}'.format(graph.name))\n",
    "        girvanNewmanClustering(graph.copy(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2E. Find the top-10 authors with highest betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"Web Mining/Information Fusion\"\"\n",
      "Top-10 authors for WebMiningInformationFusion_sub27\n",
      ">>> (0.5833333333333334, 'Vaclav Snasel')\n",
      ">>> (0.5555555555555556, 'Vojtech Svatek')\n",
      ">>> (0.3333333333333333, 'Tomas Skopal')\n",
      ">>> (0.2222222222222222, 'Pavel Moravec')\n",
      ">>> (0.2222222222222222, 'Michal Kratky')\n",
      ">>> (0.2222222222222222, 'Josef Petrak')\n",
      ">>> (0.2222222222222222, 'Jan Nemrava')\n",
      ">>> (0.2222222222222222, 'Jan Martinovic')\n",
      ">>> (0.2222222222222222, 'Ales Keprt')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2ca3d2aa892f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mallShortestPaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnodesBetweennessCentrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallShortestPaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Top-10 authors for {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c8ae1c604ce0>\u001b[0m in \u001b[0;36mnodesBetweennessCentrality\u001b[0;34m(listOfAllShortestPath, node, graph)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistOfAllShortestPath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mnbPathsIncludingNode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnodeIsInPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mcounterShortestPath\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prints the top-10 authors for each graph of the dataset        \n",
    "for topic, listOfGraphs in allData.items():\n",
    "    print('Topic \"{}\"\"'.format(topic))\n",
    "    for graph in listOfGraphs:\n",
    "        results = []\n",
    "        allShortestPaths = []\n",
    "        for index, vi in enumerate(np.asarray(list(nx.all_pairs_shortest_path(graph)))):\n",
    "            test = list(vi[1].values())\n",
    "            test2= sorted(test, key=lambda x: int(x[-1]))[index+1:]\n",
    "            for path in test2:\n",
    "                allShortestPaths.append(path)\n",
    "        for node in graph.nodes:\n",
    "            results.append( (nodesBetweennessCentrality(allShortestPaths, node, graph), graph.node[node]['name']) )\n",
    "        print('Top-10 authors for {}'.format(graph.name))\n",
    "        for tuple in sorted(results, reverse=True)[:10]:\n",
    "            print('>>> {}'.format(tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example with a single graph: TO DELETE FOR THE FINALE VERSION BUT IS CURRENTLY A PROOF THAT THE ALGORITHM WORKS \n",
    "                            #AS IS PRODUCES THE SAME RESULT THAN THE NETWORKX FUNCTION \n",
    "graph = allData[\"Web Mining/Information Fusion\"][2].copy()\n",
    "print(\"Here are the results given by networkX \\n\",nx.betweenness_centrality(graph,endpoints=True))\n",
    "results = []\n",
    "\n",
    "allShortestPaths = []\n",
    "for index, vi in enumerate(np.asarray(list(nx.all_pairs_shortest_path(graph)))):\n",
    "    test = list(vi[1].values())\n",
    "    test2= sorted(test, key=lambda x: int(x[-1]))[index+1:]\n",
    "    for path in test2:\n",
    "        allShortestPaths.append(path)\n",
    "        \n",
    "for node in graph.nodes:\n",
    "    results.append( (nodesBetweennessCentrality(allShortestPaths, node, graph), graph.node[node]['name']) )\n",
    "print('Top-10 authors for {}'.format(graph.name))\n",
    "for tuple in sorted(results, reverse=True)[:10]:\n",
    "    print('>>> {}'.format(tuple))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A. Visualize the output of Girvan-Newman algorithm by coloring nodes according to their assigned groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawGraph(G):\n",
    "    \"\"\"draws the given graph and displays the labels of each edge\"\"\"\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True)\n",
    "    nx.draw_networkx_edge_labels(G, pos)\n",
    "    plt.show()\n",
    "\n",
    "def drawGraphs(G, cnt):\n",
    "    \"\"\"Draw all different subgraphs on the same picture\"\"\"\n",
    "    test = plt.subplot(4, 3, cnt)\n",
    "    if (cnt == 1):\n",
    "        test.title.set_text('Initial state of the graph')\n",
    "    else:\n",
    "        test.title.set_text('State of the graph at iteration: {}, number of communities: {}'.format(cnt-1, nx.number_connected_components(G)))\n",
    "    test.set_yticklabels([])\n",
    "    test.set_xticklabels([])\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw_networkx(G, pos)\n",
    "    nx.draw_networkx_edge_labels(G, pos)\n",
    "\n",
    "def drawColoredGraph(G):\n",
    "    \"\"\"# draws a graph where communities are drawn using different colors\"\"\"\n",
    "    test = plt.subplot(4,3,12)\n",
    "    test.set_yticklabels([])\n",
    "    test.set_xticklabels([])\n",
    "    test.title.set_text('Resulting communities ({})'.format(nx.number_connected_components(G)))\n",
    "    pos = nx.spring_layout(G)\n",
    "    connected_components = nx.connected_component_subgraphs(G)\n",
    "    for index, sg in enumerate(connected_components):\n",
    "        r = lambda: random.randint(0,255)\n",
    "        randomColor =('#%02X%02X%02X' % (r(),r(),r()))\n",
    "        nx.draw_networkx(sg, pos = pos, node_color = str(randomColor), with_labels= False, edgelist=[])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs Girvan-Newman for every graph in the dataset and visualize the output\n",
    "for topic, listOfGraphs in allData.items():\n",
    "    print('>>> Topic \"{}\"\"'.format(topic))\n",
    "    for graph in listOfGraphs:\n",
    "        print('> Girvan-Newman clustering for {}'.format(graph.name))\n",
    "        girvanNewmanClustering(graph.copy(), 10, visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B. Visualize the network and highlight the top 10 authors with the highest betweenness centrality and top 10 edges with the highest betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
